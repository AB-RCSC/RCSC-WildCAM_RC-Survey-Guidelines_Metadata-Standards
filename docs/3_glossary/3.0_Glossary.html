

<!DOCTYPE html>


<html >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Glossary &#8212; Remote Camera Survey Guidelines - Guidelines for Western Canada</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=e353d410970836974a52" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=e353d410970836974a52" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" href="../_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=e353d410970836974a52" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52" />

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = '3_glossary/3.0_Glossary';</script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="prev" title="Appendix A" href="../2_metadata-standards/2.18_AppendixA.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="None"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
  

<a class="navbar-brand logo" href="../intro.html">
  
  
  
  
    
    
      
    
    
    <img src="../_static/logo.png" class="logo__image only-light" alt="Logo image"/>
    <script>document.write(`<img src="../_static/logo.png" class="logo__image only-dark" alt="Logo image"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../intro.html">
                    Remote Camera Survey Guidelines & AB Metadata Standards
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Remote Camera Survey Guidelines</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../1_survey-guidelines/1.1_Citation-and-Info.html">Citation &amp; Information</a></li>
<li class="toctree-l1"><a class="reference internal" href="../1_survey-guidelines/1.2_Acknowledgments.html">Acknowledgments</a></li>
<li class="toctree-l1"><a class="reference internal" href="../1_survey-guidelines/1.3_TOC.html">Table of Contents</a></li>
<li class="toctree-l1"><a class="reference internal" href="../1_survey-guidelines/1.4_List-Tables-Figures.html">List of Tables &amp; List of Figures</a></li>

<li class="toctree-l1"><a class="reference internal" href="../1_survey-guidelines/1.5_Background.html">1.0 Background</a></li>
<li class="toctree-l1"><a class="reference internal" href="../1_survey-guidelines/1.6_Intended-Audience-and-How-to-use-this-document.html">2.0 Intended Audience and How to use this document</a></li>
<li class="toctree-l1"><a class="reference internal" href="../1_survey-guidelines/1.7_Design-hierarchy.html">3.0 Design hierarchy</a></li>
<li class="toctree-l1"><a class="reference internal" href="../1_survey-guidelines/1.8_Objectives.html">4.0 Objectives</a></li>
<li class="toctree-l1"><a class="reference internal" href="../1_survey-guidelines/1.9_Detection-probability.html">5.0 Detection probability</a></li>
<li class="toctree-l1"><a class="reference internal" href="../1_survey-guidelines/1.10_Study-design.html">6.0 Study design</a></li>
<li class="toctree-l1"><a class="reference internal" href="../1_survey-guidelines/1.11_Camera-deployment.html">7.0 Camera deployment</a></li>
<li class="toctree-l1"><a class="reference internal" href="../1_survey-guidelines/1.12_Data-management-and-processing.html">8.0 Data management and processing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../1_survey-guidelines/1.13_References.html">9.0 References</a></li>
<li class="toctree-l1"><a class="reference internal" href="../1_survey-guidelines/1.14_AppendixA-Tables.html">Appendix A - Tables</a></li>
<li class="toctree-l1"><a class="reference internal" href="../1_survey-guidelines/1.15_AppendixA-Field-Datasheets.html">Appendix A - Field Datasheets</a></li>
<li class="toctree-l1"><a class="reference internal" href="../1_survey-guidelines/1.16_AppendixB-FigureB1.html">Appendix B</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">AB Remote Camera Metadata Standards</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../2_metadata-standards/2.1_Citation-and-Info.html">Citation &amp; Information</a></li>
<li class="toctree-l1"><a class="reference internal" href="../2_metadata-standards/2.2_Preface.html">Preface</a></li>
<li class="toctree-l1"><a class="reference internal" href="../2_metadata-standards/2.3_Acknowledgments.html">Acknowledgments</a></li>
<li class="toctree-l1"><a class="reference internal" href="../2_metadata-standards/2.4_TOC.html">Table of Contents</a></li>
<li class="toctree-l1"><a class="reference internal" href="../2_metadata-standards/2.5_List-Tables-Figures.html">List of Tables &amp; List of Figures</a></li>
<li class="toctree-l1"><a class="reference internal" href="../2_metadata-standards/2.6_Purpose.html">1.0 Purpose</a></li>
<li class="toctree-l1"><a class="reference internal" href="../2_metadata-standards/2.7_Background.html">2.0 Background</a></li>
<li class="toctree-l1"><a class="reference internal" href="../2_metadata-standards/2.8_Metadata-Standards.html">3.0 Metadata Standards</a></li>
<li class="toctree-l1"><a class="reference internal" href="../2_metadata-standards/2.9_Project.html">4.0 Project</a></li>
<li class="toctree-l1"><a class="reference internal" href="../2_metadata-standards/2.10_Study-Area.html">5.0 Study Area</a></li>
<li class="toctree-l1"><a class="reference internal" href="../2_metadata-standards/2.11_Survey.html">6.0 Surveys</a></li>
<li class="toctree-l1"><a class="reference internal" href="../2_metadata-standards/2.12_Sample-Station_Camera-Location.html">7.0 Sample Station/Camera Location</a></li>
<li class="toctree-l1"><a class="reference internal" href="../2_metadata-standards/2.13_Deployment.html">8.0 Deployment</a></li>
<li class="toctree-l1"><a class="reference internal" href="../2_metadata-standards/2.14_Image_Sequence.html">9.0 Image/Sequence</a></li>
<li class="toctree-l1"><a class="reference internal" href="../2_metadata-standards/2.15_Data-Management.html">10.0 Data management</a></li>
<li class="toctree-l1"><a class="reference internal" href="../2_metadata-standards/2.16_Conclusion.html">11.0 Conclusion</a></li>
<li class="toctree-l1"><a class="reference internal" href="../2_metadata-standards/2.17_References.html">13.0 References</a></li>
<li class="toctree-l1"><a class="reference internal" href="../2_metadata-standards/2.18_AppendixA.html">Appendix A</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Glossary</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Glossary</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/CassStevenson/RCSC-WildCAM_Remote-Camera-Survey-Guidelines-and-Metadata-Standards" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/CassStevenson/RCSC-WildCAM_Remote-Camera-Survey-Guidelines-and-Metadata-Standards/issues/new?title=Issue%20on%20page%20%2F3_glossary/3.0_Glossary.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/3_glossary/3.0_Glossary.md" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.md</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>


<script>
document.write(`
  <button class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch" data-mode="light"><i class="fa-solid fa-sun"></i></span>
    <span class="theme-switch" data-mode="dark"><i class="fa-solid fa-moon"></i></span>
    <span class="theme-switch" data-mode="auto"><i class="fa-solid fa-circle-half-stroke"></i></span>
  </button>
`);
</script>

<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
  </button>
`);
</script>

</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Glossary</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="glossary">
<span id="id1"></span><h1>Glossary<a class="headerlink" href="#glossary" title="Permalink to this headline">#</a></h1>
<p id="access-method"><strong>*Access Method</strong></p>
<p>The method used to reach the camera location (e.g., on “Foot,” “ATV,” “Helicopter,” etc.).</p>
<p id="adult"><strong>*Adult</strong></p>
<p>Animals that are old enough to breed; reproductively mature.</p>
<p id="tags-age-class"><strong>Age Class</strong></p>
<p>The age classification of one or more individuals (if the classification is the same) being categorized (e.g., “Adult,” “Juvenile,” “Subadult,” “Subadult - Young of Year,” “Subadult - Yearling”, or “Unknown”).</p>
<p id="analyst"><strong>Analyst</strong></p>
<p>The first and last names of the individual who provided the observation data point (species identification and associated information). If there are multiple analysts for an observation, enter the primary analyst.</p>
<p id="animal-id"><strong>*Animal ID</strong></p>
<p>A unique ID for an animal that can be uniquely identified (e.g., marked in some way). More than one unique individual can be identified in an image; each individual should be entered as a unique row. If Animal IDs were not collected, enter “NULL.”</p>
<p id="baitlure-audible-lure"><strong>Audible lure</strong></p>
<p>Sounds imitating noises of prey or conspecifics that draw animals closer by eliciting curiosity (Schlexer, 2008).</p>
<p id="baitlure-bait"><strong>Bait</strong></p>
<p>A food item (or other substance) that is placed to attract animals via the sense of taste and olfactory cues (Schlexer, 2008).</p>
<p id="bait-lure-type"><strong>Bait/Lure Type</strong></p>
<p>The type of bait or lure used at a camera location.</p>
<p id="batteries-replaced"><strong>*Batteries Replaced</strong></p>
<p>Whether the camera’s batteries were replaced.</p>
<p id="behaviour"><strong>*Behaviour</strong></p>
<p>The behaviour of an individual or multiple individuals being categorized (e.g., “Standing,” “Drinking,” “Vigilant,” etc.).</p>
<p id="camera-active-on-arrival"><strong>*Camera Active On Arrival</strong></p>
<p>Whether a camera was functional upon arrival.</p>
<p id="camera-active-on-departure"><strong>*Camera Active On Departure</strong></p>
<p>Whether a camera was functional upon departure.</p>
<p id="camera-angle"><strong>Camera angle</strong></p>
<p>The degree at which the camera is pointed toward the FOV Target Feature relative to the horizontal ground surface (with respect to slope, if applicable).</p>
<p id="camera-attachment"><strong>*Camera Attachment</strong></p>
<p>The method/tools used to attach the camera (e.g., attached to a tree with a bungee cord; reported as codes such as “Tree + Bungee/Strap”).</p>
<p id="camera-adamaged"><strong>*Camera Damaged</strong></p>
<p>Whether the camera was damaged or malfunctioning; if there is any damage to the device (physical or mechanical), the Crew should describe the damage in the Service/Retrieval Comments.</p>
<p id="camera-days-per-camera-location"><strong>Camera days per camera location</strong></p>
<p>The number of days each camera was active and functioning during the period it was deployed (e.g., 24-hour periods or the difference in days between the Deployment Start Date Time and the Deployment End Date Time if there were no interruptions).</p>
<p id="camera-direction"><strong>*Camera Direction (degrees)</strong></p>
<p>The cardinal direction that a camera faces. Ideally, cameras should face north (N; i.e. “0” degrees), or south (S; i.e. “180” degrees) if north is not possible. The Camera Direction should be chosen to ensure the field of view (FOV) is of the original FOV target feature.</p>
<p id="camera-height"><strong>Camera Height (m)</strong></p>
<p>The height from the ground (below snow) to the bottom of the lens (recorded in metres to the nearest 0.05 m).</p>
<p id="id-camera-id"><strong>Camera ID</strong></p>
<p>A unique alphanumeric ID for the camera that distinguishes it from other cameras of the same make or model.</p>
<p id="heirch-camera-location"><strong>Camera location</strong></p>
<p>The location where a single camera was placed (recorded as “Camera Location ID”).</p>
<p id="camera-location-characteristics"><strong>*Camera Location Characteristic(s)</strong></p>
<p>Record any significant features around the camera at the time of the visit. This may include for example, manmade or natural linear features (e.g., trails), habitat types (e.g., wetlands), wildlife structure (e.g., beaver dam). Camera Location Characteristics differ from FOV target features in that Camera Location Characteristics could include those not in the camera’s Field of View (FOV).</p>
<p id="comments-camera-location-comments"><strong>*Camera Location Comments</strong></p>
<p>Comments describing additional details about a camera location.</p>
<p id="id-camera-location"><strong>Camera Location ID</strong></p>
<p>A unique alphanumeric identifier for the location where a single camera was placed (e.g., “BH1,” “BH2”).</p>
<p id="camera-make"><strong>Camera Make</strong></p>
<p>The make (i.e., the manufacturer; e.g., “Reconyx” or “Bushnell’) of a particular camera.</p>
<p id="camera-model"><strong>Camera Model</strong></p>
<p>The model number or name (e.g., “PC900” or “Trophy Cam HD”) of a particular camera.</p>
<p id="camera-serial-number"><strong>Camera Serial Number</strong></p>
<p>The serial number of a particular camera, which is usually found inside the camera cover (e.g., “P900FF04152022”).</p>
<p id="camera-spacing"><strong>Camera spacing</strong></p>
<p>The distance between cameras (i.e., also referred to as “inter-trap distance”). This will be influenced by the chosen sampling design, the survey objectives, the target species and data analysis.</p>
<p id="mods-cr-cmr"><strong>Capture-recapture (CR) model / Capture-mark-recapture (CMR) model (Karanth, 1995; Karanth &amp; Nichols, 1998)</strong></p>
<p>A method of estimating the abundance or density of marked populations using the number of animals detected and the likelihood animals will be detected (detection probability). CR (Karanth, 1995; Karanth &amp; Nichols, 1998) can be used to estimate vital rates where all newly detected unmarked animals become marked and are distinguishable in future (Efford, 2022). Spatially explicit capture-recapture (SECR; Borchers &amp; Efford, 2008; Efford, 2004; Royle &amp; Young, 2008) models have largely replaced CR and CMR models and provide more accurate density estimates (Blanc et al., 2013, Obbard et al., 2010, Sollmann et al., 2011).</p>
<p id="sd-card-status-percent-full"><strong>Card Status (% Full)</strong></p>
<p>The remaining storage capacity on an SD card; collected during a camera service or retrieval.</p>
<p id="catspim"><strong>Categorical partial identity model (catSPIM) (Augustine et al., 2019; Sun et al., 2022)</strong></p>
<p>A method used to estimate the density of partially marked populations in which the “spatial locations of where partial identity samples are captured to probabilistically resolve their complete identities” (Augustine et al., 2018, 2019). catSPIM models use partial identity traits (e.g., sex class, antler points) to help infer individual identities (Augustine et al., 2019; Sun et al., 2022). catSPIM is an extension of the SC model (Chandler &amp; Royle, 2013).</p>
<p id="sampledesign-clustered"><strong>Clustered design</strong></p>
<p>Multiple cameras are deployed at a sample station (Figure 3d). A clustered design can be used within a systematic or stratified approach (i.e., systematic clustered design or as a clustered random design [Wearn &amp; Glover-Kapfer, 2017]).</p>
<p id="sampledesign-convenience"><strong>Convenience design</strong></p>
<p>Camera locations or sample stations are chosen based on logistic considerations (e.g., remoteness, access constraints, and costs).</p>
<p id="crew-members"><strong>Crew</strong></p>
<p>The first and last names of the individuals who collected data for a deployment or a service/retrieval.</p>
<p id="cumulative-det-probability"><strong>Cumulative detection probability</strong></p>
<p>The probability of detecting a species at least once during the entire survey (Steenweg et al., 2019).</p>
<p id="density"><strong>Density</strong></p>
<p>The number of individuals per unit area.</p>
<p id="heirch-deployment"><strong>Deployment</strong></p>
<p>A user-defined group of images or video clips considered as a single “detection event” (recorded as”Sequence ID); often users choose a certain time threshold (or “inter-detection interval”) to define independent ‘events’. For example, 30 minutes (O’Brien et al., 2003; Gerber et al., 2010; Kitamura et al., 2010; Samejima et al., 2012) or 1 hour (e.g., Tobler et al., 2008; Rovero &amp; Marshall, 2009). The threshold should be recorded in the Survey Design Description).</p>
<p id="deploymnet-area-photos"><strong>Deployment area photos</strong></p>
<p>Photos of the area around the camera location, collected as a permanent, visual record of the FOV Target Features, Camera Location Characteristics, environmental conditions (e.g., vegetation, ecosite, weather) or other variables of interest. The recommendation includes collecting four photos taken from the centre of the target detection zone (Figure 5), facing each of the four cardinal directions. The documentation of the collection of these photos is recorded as “Deployment area photos taken” (Yes/No).</p>
<p id="deploymnet-area-photo-numbers"><strong>*Deployment Area Photo Numbers</strong></p>
<p>The image numbers for the deployment area photos (if collected, e.g., “DSC100”). These are optionally documented on a Camera Deployment Field Datasheet for each set of camera deployment area photos. If not applicable, enter “NULL.”</p>
<p id="deployment-area-photos-taken"><strong>*Deployment Area Photos Taken</strong></p>
<p>Whether deployment area photos were taken (yes/no; optional). The recommendation includes collecting four photos taken from the centre of the target detection zone (Figure 5), facing each of the four cardinal directions.</p>
<p id="comments-deployment-comments"><strong>*Deployment Comments</strong></p>
<p>Comments describing additional details about the deployment.</p>
<p id="crew-deployment"><strong>Deployment Crew</strong></p>
<p>The first and last names of the individuals who collected data during the deployment visit.</p>
<p id="deployment-end-date-time"><strong>Deployment End Date Time (DD-MMM-YYYY HH:MM:SS)</strong></p>
<p>The date and time that the data was retrieved for a specific deployment (e.g., 27-JUL-2019 23:00). The deployment end date time may not coincide with when the last image or video was collected (i.e., the Image Set End Date Time). Recording this field allows users to account for deployments where no images were captured and to confirm the last date and time that the camera was active.</p>
<p id="id-deployment-id"><strong>Deployment ID</strong></p>
<p>A unique alphanumeric identifier for a unique camera deployed during a specific survey period (ideally recorded as: “Camera Location ID”_”Deployment Start Date” (or …”Deployment End Date”) (e.g., “BH1_17-JUL-2018” or “BH1_17-JUL-2018_21-JAN-2019”). Alternative naming conventions may be used, but the goal should be to minimize duplicate image names.</p>
<p id="deployment-image-count"><strong>*Deployment Image Count</strong></p>
<p>The total number of images collected during the deployment, including false fires (i.e., empty images with no species) and those triggered by a time-lapse setting.</p>
<p id="deployment-metadata"><strong>Deployment metadata</strong></p>
<p>Metadata that is collected each time a camera is deployed. Each deployment event should have its own Camera Deployment Field Datasheet. The relevant metadata fields that should be collected differ when a camera is deployed vs. serviced or retrieved. Refer to Appendix A - Table A5 and Camera Deployment Field Datasheet.</p>
<p id="deployment-start-date-time"><strong>Deployment Start Date Time (DD-MMM-YYYY HH:MM:SS)</strong></p>
<p>The date and time that a camera was placed for a specific deployment (e.g., 17-JUL-2018 10:34:22). The Deployment Start Date Time may not coincide with when the first image or video was collected (i.e., the Image Set Start Date Time). Recording this field allows users to account for deployments where no images were captured and to confirm the first date and time a camera was active.</p>
<p id="visit-deployment"><strong>Deployment visit</strong></p>
<p>When a crew has gone to a location to deploy a remote camera.</p>
<p id="detection-event"><strong>Detection “event”</strong></p>
<p>A group of images or video clips that are considered independent from other images or video clips based on a certain time threshold (or “inter-detection interval”). For example, 30 minutes (O’Brien et al., 2003; Gerber et al., 2010; Kitamura et al., 2010; Samejima et al., 2012) or 1 hour (e.g., Tobler et al., 2008; Rovero &amp; Marshall, 2009).</p>
<p id="detection-distance"><strong>Detection distance</strong></p>
<p>“The maximum distance that a sensor can detect a target” (Wearn and Glover-Kapfer, 2017).</p>
<p id="detection-probability"><strong>Detection probability (aka detectability)</strong></p>
<p>The probability (likelihood) that an individual of the population of interest is included in the count at time or location i.</p>
<p id="detection-rate"><strong>Detection rate</strong></p>
<p>The frequency of independent detections within a specified time period.</p>
<p id="detection-zone"><strong>Detection zone</strong></p>
<p>The area (conical in shape) in which a remote camera can detect the heat signature and motion of an object (Rovero &amp; Zimmermann, 2016) (Figure 5).</p>
<p id="mods-distance-sampling"><strong>Distance sampling (DS) model (Howe et al., 2017)</strong></p>
<p>A method to estimate abundance by using distances at which animals are detected (from survey lines or points) to model abundance as a function of decreasing detection probability with animal distance from the camera (using a decay function) (Cappelle et al., 2021; Howe et al., 2017).</p>
<p id="coord-easting-camera-location"><strong>Easting Camera Location</strong></p>
<p>The easting UTM coordinate of the camera location (e.g., 337875). Record using the NAD83 datum. Enter “NULL” if recording the Longitude Camera Location instead.</p>
<p id="effective-detection-distance"><strong>Effective detection distance</strong></p>
<p>The distance from a camera that would give the same number of detections if all animals up to that distance are perfectly detected, and no animals that are farther away are detected; Buckland, 1987, Becker et al., 2022).</p>
<p id="event-type"><strong>Event Type</strong></p>
<p>Whether detections were reported as an individual image captured by the camera (“Image”), a “Sequence,” or “Tag.”</p>
<p id="false-triggers"><strong>False trigger</strong></p>
<p>Blank images (no wildlife or human present). These images commonly occur when a camera is triggered by vegetation blowing in the wind.</p>
<p id="field-of-view"><strong>Field of View (FOV)</strong></p>
<p>The extent of a scene that is visible in an image (Figure 5); a large FOV is obtained by “zooming out” from a scene, whilst “zooming in” will result in a smaller FOV (Wearn &amp; Glover-Kapfer, 2017).</p>
<p>(#flash-output=) <strong>Flash output</strong></p>
<p>The camera setting that provides the level of intensity of the flash (if enabled).</p>
<p id="fov-target"><strong>FOV Target Feature</strong></p>
<p>A specific man-made or natural feature at which the camera is aimed to maximize the detection of wildlife species or to measure the use of that feature.</p>
<p id="fov-target-distance"><strong>*FOV Target Feature Distance (m)</strong></p>
<p>The distance (in metres) from the camera to the FOV Target Feature (recorded to the nearest 0.5 m). If not applicable, enter “NULL.”</p>
<p id="gps-unit-accuracy"><strong>GPS Unit Accuracy (m)</strong></p>
<p>The margin of error of the GPS unit used to record spatial information (e.g., “5” m), such as the coordinates of the camera location. On most GPS units (e.g., Garmin) this information is provided on the unit’s satellite information page.</p>
<p id="human-transport-mode-activity"><strong>*Human Transport Mode/Activity</strong></p>
<p>The activity performed, or mode of transportation used, by a human observed (e.g., hiker, skier, all terrain vehicle etc.).</p>
<p id="mods-hurdle-model"><strong>Hurdle model (Mullahy, 1986)</strong></p>
<p>A regression model used in the setting of excess zeros (zero-inflation) and overdispersion (Mullahy, 1986). Hurdle models (aka “zero-altered” models) differ from zero-inflation models in that they are two-part models, and the zero and non-zero counts are modelling separately (thus, they are only adequate when the counting process cannot generate a zero value) (Blasco-Moreno et al., 2019). relative abundance indices</p>
<p id="image"><strong>Image</strong></p>
<p>An individual image captured by a camera, which may be part of a multi-image sequence (recorded as “Image ID”).</p>
<p id="image-classification"><strong>Image classification</strong></p>
<p>The process of assigning class labels to an image according to the wildlife species, other entities (e.g., human, vehicle), or conditions within the image. Image classification can be performed manually or automatically by an artificial intelligence (AI) algorithm. Image classification is sometimes used interchangeably with “image tagging.”</p>
<p id="image-classification-confidence"><strong>Image classification confidence</strong></p>
<p>The likelihood of an image containing an object of a certain class (Fennell et al., 2022).</p>
<p id="image-flash-output"><strong>*Image Flash Output</strong></p>
<p>The Image Flash Output setting determines the level of intensity of the flash (if enabled). Record the Image Flash Output as reported in the image Exif data (e.g., “Flash Did Not Fire”, “Auto”). Record “NULL” if not applicable and “Unknown” if not known.</p>
<p id="id-image-id"><strong>Image ID</strong></p>
<p>A unique alphanumeric file name for the image. It is important to include (at a minimum) the camera location, date, time, and image number when generating an Image ID to avoid duplicate file names (e.g., “BH1_17-JUL-2018_22-JUL-2018 10:34:22_IMG_100”).</p>
<p id="image-infrared-illuminator"><strong>*Image Infrared Illuminator</strong></p>
<p>The infrared illuminator setting can be enabled, if applicable to the camera make/model, to obtain greater visibility at night by producing infrared light. Record the Image Infrared Illuminator as reported in the image Exif data (e.g., “On” or “Off”). Record “Unknown” if not known.</p>
<p id="image-processing"><strong>Image processing</strong></p>
<p>The series of operations that are taken to extract information from images. In the case of remote camera data, it can include loading the images into a processing platform, extracting information from the image metadata (e.g., the date and time the image was taken), running an artificial intelligence (AI) algorithm to identify empty images, classifying animals or other entities within the image.</p>
<p id="hierarch-image-sequence"><strong>*Image Sequence</strong></p>
<p>The order of the image in a rapid-fire sequence as reported in the image Exif data (text; e.g., “1 of 1” or “1 of 3”). Record “NULL” if not applicable.</p>
<p id="image-set-start-end-time"><strong>Image Set End Date Time (DD-MMM-YYYY HH:MM:SS)</strong></p>
<p>The date and time of the last image or video collected during a specific deployment (e.g., “17-JUL-2018 12:00:02”). The Image Set End Date Time may not coincide with the deployment end date time. Recording this field allows users to account for deployments that were conducted but for which no data was found and to confirm the last date and time a camera was active (if functioning) if no images or videos were captured prior to Service/Retrieval (especially valuable if users did not collect Time-lapse images or if the camera malfunctioned).</p>
<p id="image-set-start-date-time"><strong>Image Set Start Date Time (DD-MMM-YYYY HH:MM:SS)</strong></p>
<p>The date and time of the first image or video collected during a specific deployment (e.g., “17-JUL-2018 12:00:02”). The Image Set Start Date Time may not coincide with the Deployment Start Date Time. Recording this field allows users to confirm the first date and time a camera was active (reliable if Time-lapse images were collected; especially valuable if the user scheduled a start delay).</p>
<p id="image-tagging"><strong>Image tagging</strong></p>
<p>The process of classifying an image according to the wildlife species, other entities (e.g., human, vehicle), or conditions within the image. Image tagging may follow image classification to further classify characteristics of the individuals (e.g., age class, sex class, or behaviour) or entities within the image.</p>
<p id="image-trigger-mode"><strong>*Image Trigger Mode</strong></p>
<p>The type of trigger mode used to capture the image as reported in the image Exif data (e.g., “Time Lapse”, “Motion Detection,” “CodeLoc Not Entered,” “External Sensor”). Record “Unknown” if not known.</p>
<p id="image-sequence-comments"><strong>*Image/Sequence Comments</strong></p>
<p>Comments describing additional details about the image/sequence.</p>
<p id="image-sequence-date-time"><strong>Image/Sequence Date Time (DD-MMM-YYYY HH:MM:SS)</strong></p>
<p>The date and time of an image or sequence. Depending on the Event Type, Image/Sequence Date Time may be reported for an individual image or the first image of a unique sequence. Record as “DD-MMM-YYYY HH:MM:SS” (e.g., 22-JUL-2018 11:02:02).</p>
<p id="imperfect-detection"><strong>Imperfect detection</strong></p>
<p>Species are often detected “imperfectly,” meaning that they are not always detected when they are present (e.g., due to cover of vegetation, cryptic nature or small size) (MacKenzie et al., 2004).</p>
<p id="independent-detections"><strong>Independent detections</strong></p>
<p>Detections that are deemed to be independent based on a user-defined threshold (e.g., 30 minutes).</p>
<p id="individual-count"><strong>Individual Count</strong></p>
<p>The number of unique individuals being categorized. This may be recorded as the total number of individuals, or according to Age Class and/or Sex Class.</p>
<p id="infrared-illuminator"><strong>Infrared illuminator</strong></p>
<p>The camera setting that can be enabled (if applicable to the camera make and camera model) to obtain greater visibility at night by producing infrared light.</p>
<p id="mods-instantaneous-sampling"><strong>Instantaneous sampling (IS) (Moeller et al., 2018)</strong></p>
<p>A method used to estimate abundance or density from time-lapse images from randomly deployed cameras; the number of unique individuals (the count) is needed (Moeller et al., 2018).</p>
<p id="intensity-of-use"><strong>Intensity of use (Keim et al., 2019)</strong></p>
<p>“The expected number of use events of a specific resource unit during a unit of time… [which characterizes] how frequently a particular resource unit is used” (Keim et al., 2019). The intensity of use differs from the probability of use (which characterizes “the probability of at least one use event of that resource unit during a unit of time”; Keim et al., 2019).</p>
<p id="inter-detection-interval"><strong>Inter-detection interval</strong></p>
<p>A user-defined threshold used to define a single “detection event” (i.e., independent “events”) for group of images or video clips (e.g., 30 minutes or 1 hour). The threshold should be recorded in the Survey Design Description).</p>
<p id="mods-inventory"><strong>Inventory</strong></p>
<p>Rapid assessment surveys to determine what species are present in a given area at a given point in time; there is no attempt made to quantify aspects of communities or populations (Wearn &amp; Glover-Kapfer, 2017).</p>
<p id="age-class-juvenile"><strong>Juvenile</strong></p>
<p>Animals in their first summer, with clearly juvenile features (e.g., spots); mammals older than neonates but that still require parental care.</p>
<p id="kernel-density-estimator"><strong>Kernel density estimator</strong></p>
<p>The probability of “utilization” (Jennrich &amp; Turner, 1969); describes the relative probability of use (Powell &amp; Mitchell, 2012).</p>
<p id="key-id"><strong>*Key ID</strong></p>
<p>The unique ID for the specific key or set of keys used to lock/secure the camera to the post, tree, etc.</p>
<p id="coord-latitude-camera-location"><strong>Latitude Camera Location</strong></p>
<p>The latitude of the camera location in decimal degrees to five decimal places (e.g., 53.78136). Enter “NULL” if recording the Northing Camera Location instead.</p>
<p id="coord-longitude-camera-location"><strong>Longitude Camera Location</strong></p>
<p>The longitude of the camera location in decimal degrees to five decimal places (e.g., -113.46067). Enter “NULL” if recording the Easting Camera Location instead.</p>
<p id="baitlure-lure"><strong>Lure</strong></p>
<p>Any substance that draws animals closer; lures include scent (olfactory) lure, visual lure and audible lure (Schlexer, 2008).</p>
<p id="typeid-marked"><strong>Marked individuals / populations / species</strong></p>
<p>Individuals, populations, or species (varies with modelling approach and context) that can be identified using natural or artificial markings (e.g., coat patterns, scars, tags, collars).</p>
<p id="mods-marked-resight"><strong>Mark-resight (MR) model (Arnason et al., 1991; McClintock et al., 2009)</strong></p>
<p>A method used to estimate the abundance of partially marked populations using the number of marked individuals, the number of unmarked individuals, and the detection probability from marked animals (Wearn &amp; Glover-Kapfer, 2017). MR is similar to capture-recapture (CR; Karanth, 1995; Karanth &amp; Nichols, 1998) models, except only a portion of animals are individually identified.</p>
<p id="metadata"><strong>Metadata</strong></p>
<p>Data that provides information about other data (e.g., the number of images on an SD card).</p>
<p id="mods-modelling-assumption"><strong>Model assumption</strong></p>
<p>Explicitly stated (or implicitly premised) conventions, choices and other specifications (e.g., about the data, wildlife ecology/behaviour, the relationships between variables, etc.) on which a particular modelling approach is based that allows the model to provide valid inference.</p>
<p id="mods-modelling-approach"><strong>Modelling approach</strong></p>
<p>The method used to analyze the camera data, which should depend on the state variable, e.g., occupancy models [MacKenzie et al., 2002], spatially explicit capture recapture (SECR) for density estimation [Chandler and Royle, 2013], etc. and the target species.</p>
<p id="settings-motion-image-interval"><strong>Motion Image Interval (seconds)</strong></p>
<p>The time (in seconds) between images within a multi-image sequence that occur due to motion, heat, or activation of external detector devices. The Motion Image Interval is pre-set in the camera’s settings by the user, but the time at which the camera collects images because of this setting is influenced by the presence of movement or heat. For example, if the camera was set to take 3 images per event at a Motion Image Interval of 3 seconds when the camera detects motion or heat, the first image will be collected (e.g., at 09:00:00), the second image will be collected 3 seconds later (09:00:03), and the third will be collected 3 seconds after that (09:00:06). This setting differs from the Quiet Period in that the delay occurs between images contained within a multi-image sequence, rather than between multi-image sequences (as in quiet period). If a Motion Image Interval was not set, enter “0” seconds (i.e., instantaneous).</p>
<p id="mods-negative-binomial"><strong>Negative binomial (NB) regression (Mullahy, 1986)</strong></p>
<p>A regression model used for count data with overdispersion but without zero-inflation. relative abundance indices</p>
<p id="mods-n-mixture-model"><strong>N-mixture models</strong></p>
<p>A class of models for estimating absolute abundance using replicated counts of animals from several different sites; site-specific counts are treated as independent random variables to estimate the number of animals available for capture at each site; detection is imperfect (Royle 2004). N-mixture models are a type of site-structured model (i.e., that “treat each camera as though it samples… [a] distinct population within a larger meta-population” [Clarke et al., 2023]).</p>
<p id="coord-northing-camera-location"><strong>Northing Camera Location</strong></p>
<p>The northing UTM coordinate of the camera location (e.g., “5962006”). Record using the NAD83 datum. Enter “NULL” if recording the Latitude Camera Location instead.</p>
<p id="number-of-images"><strong>*# Of Images</strong></p>
<p>The number of images on an SD card.</p>
<p id="occupancy"><strong>Occupancy</strong></p>
<p>The probability a site is occupied by the species.</p>
<p id="mods-occupancy-model"><strong>Occupancy model (MacKenzie et al., 2002)</strong></p>
<p>A modelling approach used to account for imperfect detection by first evaluating the detection probability of a species via detection histories (i.e., present or absent) to determine the probability of the true presence or absence of a species at a site (MacKenzie et al., 2002).</p>
<p id="mods-overdispersion"><strong>Overdispersion</strong></p>
<p>A variance significantly larger than the mean (Bliss &amp; Fisher, 1953); greater variability in a set of data than predicted by the error structure of the model (Harrison et al., 2018); excess variability can be caused by zero inflation, non-independence of counts, or both (Zuur et al., 2009).</p>
<p id="sampledesign-paired"><strong>Paired design</strong></p>
<p>A form of clustered design when two cameras that are placed closely together to increase detection probability (“paired cameras”) or to evaluate certain conditions (“paired sites”, e.g., on- or off trails). Paired placements can help to account for other variability that might occur (i.e., variation in habitat quality).</p>
<p id="typeid-partially-marked"><strong>Partially marked individuals / populations / species</strong></p>
<p>Individuals, populations, or species (varies with modelling approach and context) that have a suite of partially identifying traits (e.g., antler points, sex class, age class). For populations/species, those in which a proportion of individuals carry marks or in which individuals themselves are partially marked.</p>
<p id="settings-photos-per-trigger"><strong>Photos Per Trigger</strong></p>
<p>The camera setting that describes the number of photos taken each time the camera is triggered.</p>
<p id="mods-poisson-regression"><strong>Poisson regression</strong></p>
<p>A regression model for count data used when data are not overdispersed or zero-inflated (Lambert, 1992). relative abundance indices</p>
<p id="heirch-project"><strong>Project</strong></p>
<p>A scientific study, inventory or monitoring program that has a certain objective, defined methods, and a defined boundary in space and time (recorded as <strong>“Project ID”</strong>).</p>
<p id="project-coordinator"><strong>Project Coordinator</strong></p>
<p>The first and last name of the primary contact for the project.</p>
<p id="project-coordinator-email"><strong>Project Coordinator Email</strong></p>
<p>The email address of the project coordinator.</p>
<p id="project-description"><strong>Project Description</strong></p>
<p>A description of the project objective(s) and general methods.</p>
<p id="id-project"><strong>Project ID</strong></p>
<p>A unique alphanumeric identifier for each project (e.g., “UofA_WildEdmonton-Urban-Wildlife-Monitoring_2018”).</p>
<p id="psuedoreplication"><strong>Pseudoreplication</strong></p>
<p>When observations are not statistically independent (spatially or temporally) but are treated as if they are independent.</p>
<p id="purpose-of-visit"><strong>Purpose of Visit</strong></p>
<p>The reason for visiting the camera location (i.e. to deploy the camera [“Deployment”], retrieve the camera [“Retrieve”] or to change batteries/SD card or replace the camera [“Service”]).</p>
<p id="settings-quiet-period"><strong>Quiet Period (seconds)</strong></p>
<p>The user-defined camera setting which provides the time (in seconds) between shutter “triggers” if the camera was programmed to pause between firing initially and firing a second time. Also known as “time lag” (depending on the Camera Make and Camera Model; Palmer et al., 2018). Report as “0” if a Quiet Period was not set. The Quiet Period differs from the Motion Image Interval in that the delay occurs between multi-image sequences rather than between the images contained within multi-image sequences (as in the Motion Image Interval).</p>
<p id="sampledesign-random"><strong>Random (or “simple random”) design</strong></p>
<p>Randomized camera locations (or sample stations) across the area of interest, sometimes with a predetermined minimum distance between camera locations (or sample stations).</p>
<p id="mods-rest"><strong>Random encounter and staying time (REST) model (Nakashima et al., 2017)</strong></p>
<p>A recent modification of the REM (Nakashima et al., 2017) that substitutes staying time (i.e., the cumulative time in the cameras’ detection zone) for movement speed (staying time and movement speed are inversely proportional) (Cappelle et al., 2021).</p>
<p id="mods-rem"><strong>Random encounter model (REM) (Rowcliffe et al., 2008, 2013)</strong></p>
<p>A method used to estimate the density of unmarked populations; uses the rate of independent captures, an estimate of movement rate, average group size, and the area sampled by the remote camera.</p>
<p id="equip-recovery-time"><strong>Recovery time</strong></p>
<p>The time necessary for the camera to prepare to capture the next photo after the previous one has been recorded (Trolliet et al., 2014).</p>
<p id="registraton-area"><strong>Registration area</strong></p>
<p>The area in which an animal entering has at least some probability of being captured on the image</p>
<p id="mods-relative-abundance"><strong>Relative abundance indices</strong></p>
<p>An index of relative abundance. When observational data is converted to a detection rate (i.e., the frequency [count] of independent detections of a species within a distinct time period). An index can be a count of animals or any sign that is expected to vary with population size (Caughley, 1977; O’Brien, 2011).</p>
<p id="remaining-battery-percent"><strong>*Remaining Battery (%)</strong></p>
<p>The remaining battery power (%) of batteries within a camera.</p>
<p id="mods-royle-nichols"><strong>Royle-Nichols model (Royle &amp; Nichols, 2003; MacKenzie et al., 2006)</strong></p>
<p>A method used to estimate population abundance or density, which assumes that individuals are counted only once per sampling occasion (Royle, 2004), but that does not require all individuals to be marked. Royle-Nichols models are a type of site-structured model (i.e., that “treat each camera as though it samples… [a] distinct population within a larger meta-population” [Clarke et al., 2023]).</p>
<p id="heirch-sample-station"><strong>Sample station</strong></p>
<p>A grouping of two or more non-independent camera locations, such as when cameras are clustered or paired (recorded as “Sample Station ID”).</p>
<p id="id-sample-station-id"><strong>Sample Station ID</strong></p>
<p>A sequential alphanumeric identifier for each camera location within a grouping of two more non-independent camera locations when cameras are deployed in clusters, pairs or arrays (e.g., “SS1” in “SS1_BH1”, “SS1_BH2”, “SS1_BH3” etc.). Record as “NULL” if this field is not applicable.</p>
<p id="baitlure-scent-lure"><strong>Scent lure</strong></p>
<p>Any material that draws animals closer via their sense of smell (Schlexer, 2008).</p>
<p id="sd-card-id"><strong>*SD Card ID</strong></p>
<p>The ID label on an SD card (e.g., “CMU-100”).</p>
<p id="sd-card-replaced"><strong>*SD Card Replaced</strong></p>
<p>Whether the SD card was replaced.</p>
<p id="security"><strong>*Security</strong></p>
<p>The equipment used to secure the camera (e.g., “Security box,” “Bracket,” “Bracket + Screws,” or “None”).</p>
<p id="heirarch-sequence"><strong>Sequence</strong></p>
<p>A user-defined group of images or video clips considered as a single “detection event” (recorded as”Sequence ID”); often users choose a certain time threshold (or “inter-detection interval”) to define independent “events”; e.g., 30 minutes or 1 hour. The threshold should be recorded in the Survey Design Description).</p>
<p id="id-sequence-id"><strong>Sequence ID</strong></p>
<p>A unique alphanumeric for a multi-image sequence. The Sequence ID should ideally consist of the Deployment ID and the names of the first and last images and videos in the sequence (separated by “<em>”) (i.e., “<em>Deployment ID</em>”</em>”IMG_#[name of first image in sequence]”<em>”IMG</em>#”[name of last image in sequence] (e.g.,”BH1_22-JUL-2018 IMG_001-IMG_005”).</p>
<p id="service-retrieval"><strong>Service/Retrieval</strong></p>
<p>When a crew has gone to a location to service or retrieve a remote camera.</p>
<p id="comments-service-retrieval"><strong>*Service/Retrieval Comments</strong></p>
<p>Comments describing additional details about the service/retrieval.</p>
<p id="crew-service-retrieval"><strong>Service/Retrieval Crew</strong></p>
<p>The first and last names of the individuals who collected data during the service/retrieval visit.</p>
<p id="metadata-service-retrieval"><strong>Service/Retrieval metadata</strong></p>
<p>Metadata that should be collected each time a camera location is visited to service or retrieve a camera, including data on any change to the camera location, sampling period, and/or setting type (e.g., not baited and then baited later). The relevant metadata fields that should be collected differ when a camera is deployed vs. serviced or retrieved. Refer to Appendix - Table A5 and the Camera Service/Retrieval Field Datasheet.</p>
<p id="visit-service-retrieval"><strong>Service/Retrieval visit</strong></p>
<p>When a crew has gone to a location to service or retrieve a remote camera.</p>
<p id="tags-sex-class"><strong>Sex Class</strong></p>
<p>The sex classification of an individual or multiple individuals (if the classification is the same) being categorized (e.g., “Male,” “Female,” or “Unknown”).</p>
<p id="mods-ste"><strong>Space-to-event (STE) model (Moeller et al., 2018)</strong></p>
<p>A method used to estimate abundance or density that accounts for variable detection probability through the use of time-lapse images and is unaffected by animal movement rates (collapses sampling intervals to an instant in time, and thus estimates are unaffected by animal movement rates) (Moeller et al., 2018).</p>
<p id="spatial-autocorrelation"><strong>Spatial autocorrelation</strong></p>
<p>The tendency for locations that are closer together to be more similar.</p>
<p id="mods-sc"><strong>Spatial count (SC) model / Unmarked spatial capture-recapture (Chandler &amp; Royle, 2013)</strong></p>
<p>A method used to estimate the density of unmarked populations; similar to SECR (Borchers &amp; Efford, 2008; Efford, 2004; Royle &amp; Young, 2008; Royle et al., 2009); however, SC models account for individuals’ unknown identities using the spatial pattern of detections (Chandler &amp; Royle, 2013; Sun et al., 2022). SC uses trap-specific counts to estimate the location and number of activity centres to estimate density.</p>
<p id="mods-smr"><strong>Spatial mark-resight (SMR) (Chandler &amp; Royle, 2013; Sollmann et al., 2013a, 2013b)</strong></p>
<p>A method used to estimate the density of “partially marked populations by combining… [detection] histories of marked [individuals] and counts of unmarked [individuals]” (Doran-Myers, 2018) over several occasions (Sollman et al., 2013a; Rich et al., 2014; Whittington et al., 2018). SMR models can be implemented using different statistical frameworks, including Bayesian estimation (Royle and Young, 2008; Morin et al., 2022).</p>
<p id="mods-2flankspim"><strong>Spatial partial identity model (2-flank SPIM) (Augustine et al., 2018)</strong></p>
<p>A method used to estimate the density of partially marked populations in which the “spatial locations of where partial identity samples are captured to probabilistically resolve their complete identities” (Augustine et al., 2018). Paired sampling design is commonly used to capture both the right and left flanks of an animal to resolve individual identities (Augustine et al., 2018). 2-flank SPIM is an extension of the SCR model (Borchers &amp; Efford, 2008; Efford, 2004; Royle &amp; Young, 2008; Royle et al., 2009).</p>
<p id="mods-scr-secr"><strong>Spatially explicit capture-recapture (SECR) / Spatial capture-recapture (SCR) (Borchers &amp; Efford, 2008; Efford, 2004; Royle &amp; Young, 2008; Royle et al., 2009)</strong></p>
<p>The SECR (or SCR) method is used to estimate the density of marked populations; an extension of traditional capture-recapture (CR; Karanth, 1995; Karanth &amp; Nichols, 1998) models (Karanth, 1995; Karanth &amp; Nichols, 1998) that explicitly accounts for camera location and animal movement (Burgar et al., 2018). SECR models use spatially referenced individual capture histories to infer where animals’ home range centres are, assuming that detection probability decreases with increasing distance between cameras and home range centres (Clarke et al., 2023). SECR models can be implemented using different statistical frameworks, including Bayesian estimation (Royle and Young, 2008; Morin et al., 2022).</p>
<p id="species"><strong>Species</strong></p>
<p>The capitalized common name of the species being categorized (“tagged”) in the tag, image or sequence.</p>
<p id="stake-distance"><strong>*Stake Distance (m)</strong></p>
<p>The distance from the camera to a stake (in metres to the nearest 0.05 m). If not applicable, enter “NULL.”</p>
<p id="state-variable"><strong>State variable</strong></p>
<p>A formal measure that summarizes the state of a community or population at a particular time (Wearn &amp; Glover-Kapfer, 2017), e.g., species richness or population abundance.</p>
<p id="sampledesign-stratified"><strong>Stratified design</strong></p>
<p>The area of interest is divided into smaller strata (e.g., habitat type, disturbance levels), and cameras are placed within each stratum (e.g., 15%, 35% and 50% of sites within high, medium, and low disturbance strata).</p>
<p id="sampledesign-stratified-random"><strong>Stratified random design (Figure 3c)</strong></p>
<p>The area of interest is divided into smaller strata (e.g., habitat type, disturbance levels), and then a proportional random sample of sites is selected within each stratum (e.g., 15%, 35% and 50% of sites within high, medium and low disturbance strata).</p>
<p id="hierarch-study-area"><strong>Study area</strong></p>
<p>A unique research, inventory or monitoring area (spatial boundary) within a project (there may be multiple study areas within a single project) (recorded as “Study Area ID”).</p>
<p id="study-area-description"><strong>Study Area Description</strong></p>
<p>A description for each unique research or monitoring area including its location, the habitat type(s), land use(s) and habitat disturbances (where applicable).</p>
<p id="id-study-area"><strong>Study Area ID</strong></p>
<p>A unique alphanumeric identifier for each study area (e.g.,”OILSANDS_REF1,” “OILSANDS_REF2”). If only one area was surveyed, the Project ID and Study Area ID should be the same.</p>
<p id="age-class-subadult"><strong>Subadult</strong></p>
<p>Animals older than a “Juvenile” but not yet an “Adult”; a “Subadult” may be further classified into “Young of the Year” or “Yearling.”</p>
<p id="age-class-subadult-yearling"><strong>Subadult - Yearling</strong></p>
<p>Animals approximately one year old; has lived through one winter season; between “Young of Year” and “Adult.”</p>
<p id="age-class-subadult-year-of-young"><strong>Subadult - Young of Year</strong></p>
<p>Animals less than one year old; born in the previous year’s spring, but has not yet lived through a winter season; between “Juvenile” and “Yearling.”</p>
<p id="hierarch-survey"><strong>Survey</strong></p>
<p>A unique deployment period (temporal extent) within a project (recorded as “Survey ID”).</p>
<p id="surveydesign"><strong>Survey Design</strong></p>
<p>The spatial arrangement of remote cameras within the study area.</p>
<p id="surveydesigndescription"><strong>*Survey Design Description</strong></p>
<p>A description of any additional details about the survey design.</p>
<p id="id-survey"><strong>Survey ID</strong></p>
<p>A unique alphanumeric identifier for each survey period (e.g., “FORTMC_001”).</p>
<p id="survey-objectives"><strong>Survey Objectives</strong></p>
<p>The specific objectives of each survey within a project. Survey objectives should be specific, measurable, achievable, relevant, and time-bound (i.e., SMART). Objectives may include include the Target Species, the state variables, proposed modelling approach(es) and the variables of interest (e.g., occupancy, density). If a project has only one survey or multiple surveys with identical methods and locations, the project and Survey Objectives may be the same. Otherwise, the differences between each unique survey should be documented carefully.</p>
<p id="sampledesign-systematic"><strong>Systematic design (Figure 3b)</strong></p>
<p>Camera locations occur in a regular pattern (e.g., a grid pattern) across the study area.</p>
<p id="sampledesign-systematic-random"><strong>Systematic random design</strong></p>
<p>Camera locations are selected using a two-stage approach. Firstly, girds are selected systematically (to occur within a regular pattern) across the study area. The location of the camera within each grid is then selected randomly.</p>
<p id="tag"><strong>Tag</strong></p>
<p>When individuals or groups of individuals are categorized within images, regardless of whether the information applies to all of the individuals in the image.</p>
<p id="target-species"><strong>Target Species</strong></p>
<p>The capitalized common name(s) of the species that the survey was designed to detect.</p>
<p id="sampledesign-targeted"><strong>Targeted design</strong></p>
<p>Camera locations or sample stations are placed in areas that are known or suspected to have higher activity levels (e.g., game trails, mineral licks).</p>
<p id="test-image"><strong>Test image</strong></p>
<p>An image taken from a camera after it has been set up to provide a permanent record of the visit metadata (e.g., Sample Station ID, Camera Location ID, Deployment ID, Crew, and Deployment Start Date Time [DD-MMM-YYYY HH:MM:SS]). Taking a test image can be useful to compare the information from the image to that of which was collected on the Camera Service/Retrieval Field Datasheet after retrieval and can help in reducing recording errors.</p>
<p id="test-image-taken"><strong>*Test Image Taken</strong></p>
<p>Whether a test image (i.e., an image taken from a camera after it has been set up to provide a permanent record of the visit metadata) was taken. Arm the camera, from ~5 m in front, walk towards the camera while holding the Test Image Sheet (see next page).</p>
<p id="mods-tifc"><strong>Time in front of the camera (TIFC) (Huggard, 2018; Warbington &amp; Boyce, 2020; tested in Becker et al., 2022)</strong></p>
<p>A method used to estimate density that treats camera image data as quadrat samples (Becker et al., 2022).</p>
<p id="timelapse-images"><strong>Time-lapse image</strong></p>
<p>Images that are taken at regular intervals (e.g., hourly or daily, on the hour). It is critical to take a minimum of one time-lapse image per day at a consistent time (e.g., 12:00 pm [noon]) to create a record of camera functionality and local environmental conditions (e.g., snow cover, plant growth, etc.). Time-lapse images may always be useful for modelling approaches that require estimation of the “viewshed” (“viewshed density estimators” such as REM or time-to-event (TTE) models; see Moeller et al., [2018] for advantages and disadvantages).</p>
<p id="timelapse-interval"><strong>Time-lapse interval (minutes)</strong></p>
<p>The camera setting which provides the time (in minutes) between automated, regularly timed recording events (triggers) when the camera is set to take photos at defined time intervals. The time-lapse interval is pre-set in the camera’s settings by the user; the time at which the camera collects images because of this setting is not influenced by the presence of movement or heat (as opposed to Motion Image Interval). If time-lapse images were not collected (and thus, no time-lapse interval was defined), this field should be reported as “NULL.”</p>
<p id="mods-tte"><strong>Time-to-event (TTE) model (Moeller et al., 2018)</strong></p>
<p>A method used to estimate abundance or density from the detection rate while accounting for animal movement rates (Moeller et al., 2018). The TTE model assumes perfect detection (though there is a model extension to account for imperfect detection that requires further testing).</p>
<p id="total-number-of-camera-days"><strong>Total number of camera days</strong></p>
<p>The number of days that all cameras were active during the survey.</p>
<p id="trigger-event"><strong>Trigger “event”</strong></p>
<p>An activation of the camera detector(s) that initiates the capture of a single or multiple images, or the recording of video.</p>
<p id="settings-trigger-modes"><strong>Trigger Mode(s)</strong></p>
<p>The camera setting(s) that determine how the camera will trigger: by motion (“Motion Image”), at set intervals (“Time-lapse image”), and/or by video (“Video”; possible with newer camera models, such as Reconyx HP2X).</p>
<p id="settings-trigger-sensitivity"><strong>Trigger Sensitivity</strong></p>
<p>The camera setting responsible for how sensitive a camera is to activation (to “triggering”) via the infrared and/or heat detectors (if applicable, e.g., Reconyx HyperFire cameras have a choice between “Low,” “Low/Med,” “Med,” “Med/High,” “High,” “Very high” and “NULL”).</p>
<p id="equip-trigger-speed"><strong>Trigger speed</strong></p>
<p>The time delay necessary for the camera to shoot a photo once an animal has interrupted the infrared beam within the camera’s detection zone (Trolliet et al., 2014). Trigger speed differs from Motion Image Interval (a camera setting specified by the user) in that the trigger speed is inherent to the Camera Make and Camera Model (e.g., two different cameras, models both with a Motion Image Interval set to “no delay,” may not be able to capture images at the same speed).</p>
<p id="typeid-unmarked"><strong>Unmarked individuals / populations / species</strong></p>
<p>Individuals, populations, or species (varies with modelling approach and context) that cannot be identified using natural or artificial markings (e.g., coat patterns, scars, tags, collars). Unmarked population models rely on supplementary data (e.g., animal movement speed) and/or assumptions as a surrogate for individual identification; that is, to distinguish between multiple detections of the same individual from detections of multiple individuals when individuals do not have unique features (Gilbert et al., 2020; Morin et al., 2022).</p>
<p id="settings-user-label"><strong>User label</strong></p>
<p>A label (up to 16 characters) that can be programmed in the camera’s settings, and that will be visible in the data band of all photos and videos taken by the camera (Reconyx, 2018). It is recommended that users program the Sample Station ID/Camera Location ID as the user label, which serves as a means to confirm which Sample Station ID/Camera Location ID is associated with the images/videos.</p>
<p id="utm-zone-camera-location"><strong>UTM Zone Camera Location</strong></p>
<p>The coordinate system that divides geographic areas into north-south zones. In Alberta the UTM zones are either 11, 12, or TTM. Enter all other UTM zones in the Camera Location Comments field (e.g., zones 7-10 for British Columbia), or use latitude and longitude instead of UTM coordinates.</p>
<p id="settings-video-length"><strong>*Video Length (seconds)</strong></p>
<p>If applicable, describes the camera setting that specifies the minimum video duration (in seconds) that the camera will record when triggered. If not applicable, enter “NULL.”</p>
<p id="fov-viewshed"><strong>Viewshed</strong></p>
<p>The area visible to the camera as determined by its lens angle (in degrees) and trigger distance (Moeller et al., 2023).</p>
<p id="fov-viewshed-density-estimators"><strong>Viewshed density estimators</strong></p>
<p>Methods used to estimate the abundance of unmarked populations from observations of animals that relate animal observations to the space directly sampled by each camera’s viewshed (Moeller et al., 2023); they result in viewshed density estimates that can be extrapolated to abundance within broader sampling frames (Gilbert et al., 2020; Moeller et al., 2023).</p>
<p id="visit"><strong>Visit</strong></p>
<p>When a crew has gone to a location to deploy, service, or retrieve a remote camera.</p>
<p id="visit-comments"><strong>*Visit Comments</strong></p>
<p>Comments describing additional details about the deployment and/or service/retrieval visits.</p>
<p id="visit-metadata"><strong>Visit metadata</strong></p>
<p>Metadata that should be collected each time a camera location is visited to deploy, service or retrieve a camera. Other relevant metadata fields that should be collected differ when a camera is deployed vs. serviced or retrieved. Refer to Appendix A - Table A5, Camera Deployment Field Datasheet, and Camera Service/Retrieval Field Datasheet.</p>
<p id="baitlure-visual-lure"><strong>Visual lure</strong></p>
<p>Any material that draws animals closer via their sense of sight (Schlexer, 2008).</p>
<p id="deploy-walktest"><strong>Walktest</strong></p>
<p>A test performed to ensure the camera height, tilt, etc., adequately captures the desired detection zone. The user will 1) activate the walktest mode, 2) attach the camera at the desired height / angle, 3) walk in front of the camera to a specified distance (i.e., the “Walktest Distance,” e.g., 5 m), and 4) wave their hand in front of the camera (usually at ground level and a chosen height [i.e., the “Walktest Height,” e.g., 0.8 m]) to determine if the camera is activating (a light on the camera will flash).</p>
<p id="walktest-complete"><strong>*Walktest Complete</strong></p>
<p>Whether a walktest was performed to ensure the camera height, tilt, etc., adequately captures the desired detection zone. The user will 1) activate the walktest mode, 2) attach the camera at the desired height / angle, 3) walk in front of the camera to a specified distance (i.e., the “Walktest Distance,” e.g., 5 m), and 4) wave their hand in front of the camera (usually at ground level and a chosen height [i.e., the “Walktest Height,” e.g., 0.8 m]) to determine if the camera is activating (a light on the camera will flash).</p>
<p id="deploy-walktest-distance"><strong>*Walktest Distance (m)</strong></p>
<p>The horizontal distance (recorded in metres to the nearest 0.05 m) from the camera at which the crew performs the walktest. Record as “NULL’’ if no walktest was performed.</p>
<p id="deploy-walktest-height"><strong>*Walktest Height (m)</strong></p>
<p>The vertical distance (recorded in metres to the nearest 0.05 m) from the camera at which the crew performs the walktest. Record as “NULL’’ if no walktest was performed.</p>
<p id="mods-zinb"><strong>Zero-inflated negative binomial (ZINB) regression (McCullagh &amp; Nelder, 1989)</strong></p>
<p>A regression model used in the setting of excess zeros (zero-inflation) and overdispersion. This approach is a two-part model, where the zero-inflation is modelled separately from the counts and assumes that the count (abundance) is “conditional” on the zero-inflation model (occurrence) model. relative abundance indices</p>
<p id="mods-zip"><strong>Zero-inflated Poisson (ZIP) regression (Lambert, 1992)</strong></p>
<p>A regression model for count data that both follows the Poisson distribution and contains excess zeros (Lambert, 1992). ZIP models are only appropriate for data for which the overdispersion is not solely due to zero-inflation. relative abundance indices</p>
<p id="mods-zero-inflation"><strong>Zero-inflation</strong></p>
<p>An excess of zeros that is “so large that those expected in standard distributions (e.g., normal, Poisson, binomial, negative binomial and beta)” (Heilbron, 1994) violate the assumptions of such distributions (Martin et al., 2005). Excess zeroes can be a result of ecological effects (“true” zeros) or due to sampling or observer error (“false zeros”) (Martin et al., 2005). Excess zeroes contribute to overdispersion, but they don’t necessarily account for all excess variability (Blasco-Moreno et al., 2019).</p>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./3_glossary"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
                <footer class="bd-footer-article">
                  
<div class="footer-article-items footer-article__inner">
  
    <div class="footer-article-item"><!-- Previous / next buttons -->
<div class="prev-next-area">
    <a class="left-prev"
       href="../2_metadata-standards/2.18_AppendixA.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Appendix A</p>
      </div>
    </a>
</div></div>
  
</div>

                </footer>
              
            </div>
            
            
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Alberta Remote Camera Steering Committee (RCSC), Stevenson, C., Hubbs, A., & Wildlife Cameras for Adaptive Management (WildCAM)
</p>

  </div>
  
  <div class="footer-item">
    
  <p class="copyright">
    
      © Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=e353d410970836974a52"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>